{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How to write training scripts\n",
    "**So you don't write a separate query script each time you miss a logging statement.**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's import PyTorch and define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        torch.manual_seed(1217)\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(196, 10)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(x)\n",
    "        x = x.view(4, -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's now load the data and initialize the model, optimizer, and loss criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./mnist', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./mnist', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def eval(net):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Train the network\n",
    "1. Comment out code\n",
    "2. Copy code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.278\n",
      "[1,  4000] loss: 1.067\n",
      "[1,  6000] loss: 0.980\n",
      "[1,  8000] loss: 0.816\n",
      "[1, 10000] loss: 0.765\n",
      "[1, 12000] loss: 0.763\n",
      "[1, 14000] loss: 0.755\n",
      "Accuracy of the network on the 10000 test images: 80 %\n",
      "[2,  2000] loss: 0.576\n",
      "[2,  4000] loss: 0.596\n",
      "[2,  6000] loss: 0.541\n",
      "[2,  8000] loss: 0.567\n",
      "[2, 10000] loss: 0.545\n",
      "[2, 12000] loss: 0.550\n",
      "[2, 14000] loss: 0.546\n",
      "Accuracy of the network on the 10000 test images: 81 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "    torch.save(net.state_dict(), f'./mnist_net_{epoch}.pth')\n",
    "    torch.save(optimizer.state_dict(), f'./mnist_opt_{epoch}.pth')\n",
    "    print(\"ONCE PER EPOCH LOG STMT\")\n",
    "    eval(net)\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The pattern\n",
    "* What's the diff?\n",
    "\n",
    "* Demo\n",
    "    1. Training mode\n",
    "    2. Skip mode: Log something outside the training loop \n",
    "    2. Parallel mode: Log something inside the taining loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLI Flags\n",
    "TRAINING = False\n",
    "PROBING_TRAINING = True\n",
    "\n",
    "LO = 1\n",
    "HI = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALSO EVERY STEP 1:2000\n",
      "[2,  2000] loss: 0.576\n",
      "ALSO EVERY STEP 1:4000\n",
      "[2,  4000] loss: 0.596\n",
      "ALSO EVERY STEP 1:6000\n",
      "[2,  6000] loss: 0.541\n",
      "ALSO EVERY STEP 1:8000\n",
      "[2,  8000] loss: 0.567\n",
      "ALSO EVERY STEP 1:10000\n",
      "[2, 10000] loss: 0.545\n",
      "ALSO EVERY STEP 1:12000\n",
      "[2, 12000] loss: 0.550\n",
      "ALSO EVERY STEP 1:14000\n",
      "[2, 14000] loss: 0.546\n",
      "ONCE PER EPOCH (Confusion Matrix) 1\n",
      "Accuracy of the network on the 10000 test images: 81 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "if LO:                                                                                      #                           \n",
    "    net.load_state_dict(torch.load(f'./mnist_net_{LO - 1}.pth'))                            #\n",
    "    optimizer.load_state_dict(torch.load(f'./mnist_opt_{LO - 1}.pth'))                      # \n",
    "\n",
    "for epoch in range(LO, HI):                                                                 #\n",
    "    running_loss = 0.0\n",
    "    if TRAINING or PROBING_TRAINING:                                                        #\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print(f\"ALSO EVERY STEP {epoch}:{i+1}\")\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "        TRAINING and torch.save(net.state_dict(), f'./mnist_net_{epoch}.pth')               #\n",
    "        TRAINING and torch.save(optimizer.state_dict(), f'./mnist_opt_{epoch}.pth')         #\n",
    "    else:                                                                                   #\n",
    "        net.load_state_dict(torch.load(f'./mnist_net_{epoch}.pth'))                         #            \n",
    "        optimizer.load_state_dict(torch.load(f'./mnist_opt_{epoch}.pth'))                   #\n",
    "    print(f\"ONCE PER EPOCH (Confusion Matrix) {epoch}\")\n",
    "    eval(net)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Hindsight Logging&trade; Programming Pattern \n",
    "* Skip Retraining when possible\n",
    "    - Use memoization: observe physical-logical equivalence\n",
    "* Parallelize Retraining otherwise\n",
    "    - Enable resuming from a checkpoint\n",
    "    - Work Partitioning: Control the epoch sub-range from the command-line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beyond the Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing and Dynamically Controlling the cost of checkpointing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background checkpointing\n",
    "![Background Materialization](img/backmat-simple.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Checkpointing\n",
    "![Adaptive Checkpointing](img/adaptivity_zoomed.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-execution is embarrassingly parallel given checkpoints\n",
    "![Parallel Replay](img/initializations.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If the pattern seems like too much trouble, we can instrument the code for you automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Autoinstrument](img/changeset_example.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"800.0\"\n",
       "            src=\"https://arxiv.org/pdf/2006.07357.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fa4d78f0390>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "width = 600\n",
    "ratio = 8/6\n",
    "IFrame(\"https://arxiv.org/pdf/2006.07357.pdf\", width=width, height=ratio*width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
