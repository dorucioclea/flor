{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install flordb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "We start by selecting (or creating) a `git` repository to save our model training code as we iterate and experiment. Flor automatically commits your changes on every run, so no change is lost. Below we provide a sample repository you can use to follow along:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '../ml_tutorial'...\n",
      "remote: Enumerating objects: 56, done.\u001b[K\n",
      "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
      "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
      "remote: Total 56 (delta 20), reused 44 (delta 12), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (56/56), 15.29 KiB | 1.91 MiB/s, done.\n",
      "Resolving deltas: 100% (20/20), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone git@github.com:ucbepic/ml_tutorial ../ml_tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../ml_tutorial/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the `train.py` script to train a small linear model, \n",
    "and test your `flordb` installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/1875], Loss: 0.1726\n",
      "Epoch [1/5], Step [200/1875], Loss: 0.4662\n",
      "Epoch [1/5], Step [300/1875], Loss: 0.1456\n",
      "Epoch [1/5], Step [400/1875], Loss: 0.1074\n",
      "Epoch [1/5], Step [500/1875], Loss: 0.2317\n",
      "Epoch [1/5], Step [600/1875], Loss: 0.2387\n",
      "Epoch [1/5], Step [700/1875], Loss: 0.3520\n",
      "Epoch [1/5], Step [800/1875], Loss: 0.1224\n",
      "Epoch [1/5], Step [900/1875], Loss: 0.2337\n",
      "Epoch [1/5], Step [1000/1875], Loss: 0.0819\n",
      "Epoch [1/5], Step [1100/1875], Loss: 0.0921\n",
      "Epoch [1/5], Step [1200/1875], Loss: 0.1345\n",
      "Epoch [1/5], Step [1300/1875], Loss: 0.1298\n",
      "Epoch [1/5], Step [1400/1875], Loss: 0.0987\n",
      "Epoch [1/5], Step [1500/1875], Loss: 0.1604\n",
      "Epoch [1/5], Step [1600/1875], Loss: 0.0550\n",
      "Epoch [1/5], Step [1700/1875], Loss: 0.1614\n",
      "Epoch [1/5], Step [1800/1875], Loss: 0.0570\n",
      "Epoch [2/5], Step [100/1875], Loss: 0.0634\n",
      "Epoch [2/5], Step [200/1875], Loss: 0.2885\n",
      "Epoch [2/5], Step [300/1875], Loss: 0.0539\n",
      "Epoch [2/5], Step [400/1875], Loss: 0.3525\n",
      "Epoch [2/5], Step [500/1875], Loss: 0.0433\n",
      "Epoch [2/5], Step [600/1875], Loss: 0.0487\n",
      "Epoch [2/5], Step [700/1875], Loss: 0.1881\n",
      "Epoch [2/5], Step [800/1875], Loss: 0.0344\n",
      "Epoch [2/5], Step [900/1875], Loss: 0.1295\n",
      "Epoch [2/5], Step [1000/1875], Loss: 0.0397\n",
      "Epoch [2/5], Step [1100/1875], Loss: 0.1532\n",
      "Epoch [2/5], Step [1200/1875], Loss: 0.0844\n",
      "Epoch [2/5], Step [1300/1875], Loss: 0.0117\n",
      "Epoch [2/5], Step [1400/1875], Loss: 0.1115\n",
      "Epoch [2/5], Step [1500/1875], Loss: 0.0240\n",
      "Epoch [2/5], Step [1600/1875], Loss: 0.0350\n",
      "Epoch [2/5], Step [1700/1875], Loss: 0.0347\n",
      "Epoch [2/5], Step [1800/1875], Loss: 0.0982\n",
      "Epoch [3/5], Step [100/1875], Loss: 0.0118\n",
      "Epoch [3/5], Step [200/1875], Loss: 0.0188\n",
      "Epoch [3/5], Step [300/1875], Loss: 0.1494\n",
      "Epoch [3/5], Step [400/1875], Loss: 0.0524\n",
      "Epoch [3/5], Step [500/1875], Loss: 0.0107\n",
      "Epoch [3/5], Step [600/1875], Loss: 0.0094\n",
      "Epoch [3/5], Step [700/1875], Loss: 0.0285\n",
      "Epoch [3/5], Step [800/1875], Loss: 0.1103\n",
      "Epoch [3/5], Step [900/1875], Loss: 0.0418\n",
      "Epoch [3/5], Step [1000/1875], Loss: 0.1095\n",
      "Epoch [3/5], Step [1100/1875], Loss: 0.0193\n",
      "Epoch [3/5], Step [1200/1875], Loss: 0.0035\n",
      "Epoch [3/5], Step [1300/1875], Loss: 0.0085\n",
      "Epoch [3/5], Step [1400/1875], Loss: 0.0020\n",
      "Epoch [3/5], Step [1500/1875], Loss: 0.0581\n",
      "Epoch [3/5], Step [1600/1875], Loss: 0.0616\n",
      "Epoch [3/5], Step [1700/1875], Loss: 0.0112\n",
      "Epoch [3/5], Step [1800/1875], Loss: 0.0185\n",
      "Epoch [4/5], Step [100/1875], Loss: 0.2072\n",
      "Epoch [4/5], Step [200/1875], Loss: 0.0218\n",
      "Epoch [4/5], Step [300/1875], Loss: 0.0009\n",
      "Epoch [4/5], Step [400/1875], Loss: 0.0170\n",
      "Epoch [4/5], Step [500/1875], Loss: 0.0171\n",
      "Epoch [4/5], Step [600/1875], Loss: 0.0042\n",
      "Epoch [4/5], Step [700/1875], Loss: 0.0094\n",
      "Epoch [4/5], Step [800/1875], Loss: 0.0128\n",
      "Epoch [4/5], Step [900/1875], Loss: 0.1984\n",
      "Epoch [4/5], Step [1000/1875], Loss: 0.1630\n",
      "Epoch [4/5], Step [1100/1875], Loss: 0.0193\n",
      "Epoch [4/5], Step [1200/1875], Loss: 0.0020\n",
      "Epoch [4/5], Step [1300/1875], Loss: 0.0152\n",
      "Epoch [4/5], Step [1400/1875], Loss: 0.0407\n",
      "Epoch [4/5], Step [1500/1875], Loss: 0.0074\n",
      "Epoch [4/5], Step [1600/1875], Loss: 0.0131\n",
      "Epoch [4/5], Step [1700/1875], Loss: 0.0052\n",
      "Epoch [4/5], Step [1800/1875], Loss: 0.0083\n",
      "Epoch [5/5], Step [100/1875], Loss: 0.0071\n",
      "Epoch [5/5], Step [200/1875], Loss: 0.0039\n",
      "Epoch [5/5], Step [300/1875], Loss: 0.0381\n",
      "Epoch [5/5], Step [400/1875], Loss: 0.0119\n",
      "Epoch [5/5], Step [500/1875], Loss: 0.0075\n",
      "Epoch [5/5], Step [600/1875], Loss: 0.0027\n",
      "Epoch [5/5], Step [700/1875], Loss: 0.0066\n",
      "Epoch [5/5], Step [800/1875], Loss: 0.0054\n",
      "Epoch [5/5], Step [900/1875], Loss: 0.0081\n",
      "Epoch [5/5], Step [1000/1875], Loss: 0.0448\n",
      "Epoch [5/5], Step [1100/1875], Loss: 0.0107\n",
      "Epoch [5/5], Step [1200/1875], Loss: 0.0030\n",
      "Epoch [5/5], Step [1300/1875], Loss: 0.0201\n",
      "Epoch [5/5], Step [1400/1875], Loss: 0.0074\n",
      "Epoch [5/5], Step [1500/1875], Loss: 0.1377\n",
      "Epoch [5/5], Step [1600/1875], Loss: 0.0131\n",
      "Epoch [5/5], Step [1700/1875], Loss: 0.0570\n",
      "Epoch [5/5], Step [1800/1875], Loss: 0.0078\n",
      "Accuracy of the network on the 10000 test images: 97.88 %\n",
      "Flor wrote log records locally.\n"
     ]
    }
   ],
   "source": [
    "! python train.py --flor myFirstRun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flor will manage checkpoints, logs, command-line arguments, code changes, and other experiment metadata on each run (More details [below](#storage--data-layout)). All of this data is then expesed to the user via SQL or Pandas queries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View your experiment history\n",
    "From the same directory you ran the examples above, open an iPython terminal, then load and pivot the log records.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>projid</th>\n",
       "      <th>runid</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>vid</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>loss</th>\n",
       "      <th>lr</th>\n",
       "      <th>epochs</th>\n",
       "      <th>hidden</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>myFirstRun</td>\n",
       "      <td>2023-07-20T13:31:46</td>\n",
       "      <td>14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.17260010540485382</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>myFirstRun</td>\n",
       "      <td>2023-07-20T13:31:46</td>\n",
       "      <td>14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.46620410680770874</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>myFirstRun</td>\n",
       "      <td>2023-07-20T13:31:46</td>\n",
       "      <td>14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>0.14557793736457825</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>myFirstRun</td>\n",
       "      <td>2023-07-20T13:31:46</td>\n",
       "      <td>14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>0.10743971914052963</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>myFirstRun</td>\n",
       "      <td>2023-07-20T13:31:46</td>\n",
       "      <td>14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.23169249296188354</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           projid       runid               tstamp  \\\n",
       "0  ml_tutorial_flor.shadow.readme  myFirstRun  2023-07-20T13:31:46   \n",
       "1  ml_tutorial_flor.shadow.readme  myFirstRun  2023-07-20T13:31:46   \n",
       "2  ml_tutorial_flor.shadow.readme  myFirstRun  2023-07-20T13:31:46   \n",
       "3  ml_tutorial_flor.shadow.readme  myFirstRun  2023-07-20T13:31:46   \n",
       "4  ml_tutorial_flor.shadow.readme  myFirstRun  2023-07-20T13:31:46   \n",
       "\n",
       "                                        vid  epoch  step                 loss  \\\n",
       "0  14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1      1   100  0.17260010540485382   \n",
       "1  14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1      1   200  0.46620410680770874   \n",
       "2  14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1      1   300  0.14557793736457825   \n",
       "3  14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1      1   400  0.10743971914052963   \n",
       "4  14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1      1   500  0.23169249296188354   \n",
       "\n",
       "      lr epochs hidden batch_size  \n",
       "0  0.001      5    500         32  \n",
       "1  0.001      5    500         32  \n",
       "2  0.001      5    500         32  \n",
       "3  0.001      5    500         32  \n",
       "4  0.001      5    500         32  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flor import full_pivot, log_records\n",
    "df = full_pivot(log_records())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run some more experiments\n",
    "The `train.py` script has been prepared in advance to define and manage four different hyper-parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_size = flor.arg(\"hidden\", default=500)\n",
      "num_epochs = flor.arg(\"epochs\", 5)\n",
      "batch_size = flor.arg(\"batch_size\", 32)\n",
      "learning_rate = flor.arg(\"lr\", 1e-3)\n"
     ]
    }
   ],
   "source": [
    "%cat train.py | grep flor.arg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can control any of the hyper-parameters (e.g. `hidden`) using Flor's command-line interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/1875], Loss: 0.7625\n",
      "Epoch [1/5], Step [200/1875], Loss: 0.4340\n",
      "Epoch [1/5], Step [300/1875], Loss: 0.3457\n",
      "Epoch [1/5], Step [400/1875], Loss: 0.4310\n",
      "Epoch [1/5], Step [500/1875], Loss: 0.3177\n",
      "Epoch [1/5], Step [600/1875], Loss: 0.3360\n",
      "Epoch [1/5], Step [700/1875], Loss: 0.1061\n",
      "Epoch [1/5], Step [800/1875], Loss: 0.2862\n",
      "Epoch [1/5], Step [900/1875], Loss: 0.4795\n",
      "Epoch [1/5], Step [1000/1875], Loss: 0.3659\n",
      "Epoch [1/5], Step [1100/1875], Loss: 0.1897\n",
      "Epoch [1/5], Step [1200/1875], Loss: 0.1757\n",
      "Epoch [1/5], Step [1300/1875], Loss: 0.1298\n",
      "Epoch [1/5], Step [1400/1875], Loss: 0.3751\n",
      "Epoch [1/5], Step [1500/1875], Loss: 0.2477\n",
      "Epoch [1/5], Step [1600/1875], Loss: 0.1193\n",
      "Epoch [1/5], Step [1700/1875], Loss: 0.6109\n",
      "Epoch [1/5], Step [1800/1875], Loss: 0.1453\n",
      "Epoch [2/5], Step [100/1875], Loss: 0.3296\n",
      "Epoch [2/5], Step [200/1875], Loss: 0.1020\n",
      "Epoch [2/5], Step [300/1875], Loss: 0.4109\n",
      "Epoch [2/5], Step [400/1875], Loss: 0.0651\n",
      "Epoch [2/5], Step [500/1875], Loss: 0.0818\n",
      "Epoch [2/5], Step [600/1875], Loss: 0.0933\n",
      "Epoch [2/5], Step [700/1875], Loss: 0.0484\n",
      "Epoch [2/5], Step [800/1875], Loss: 0.1521\n",
      "Epoch [2/5], Step [900/1875], Loss: 0.0934\n",
      "Epoch [2/5], Step [1000/1875], Loss: 0.3964\n",
      "Epoch [2/5], Step [1100/1875], Loss: 0.2923\n",
      "Epoch [2/5], Step [1200/1875], Loss: 0.1894\n",
      "Epoch [2/5], Step [1300/1875], Loss: 0.0374\n",
      "Epoch [2/5], Step [1400/1875], Loss: 0.1978\n",
      "Epoch [2/5], Step [1500/1875], Loss: 0.1141\n",
      "Epoch [2/5], Step [1600/1875], Loss: 0.0918\n",
      "Epoch [2/5], Step [1700/1875], Loss: 0.3388\n",
      "Epoch [2/5], Step [1800/1875], Loss: 0.2529\n",
      "Epoch [3/5], Step [100/1875], Loss: 0.0759\n",
      "Epoch [3/5], Step [200/1875], Loss: 0.1016\n",
      "Epoch [3/5], Step [300/1875], Loss: 0.2257\n",
      "Epoch [3/5], Step [400/1875], Loss: 0.0070\n",
      "Epoch [3/5], Step [500/1875], Loss: 0.1830\n",
      "Epoch [3/5], Step [600/1875], Loss: 0.1712\n",
      "Epoch [3/5], Step [700/1875], Loss: 0.0641\n",
      "Epoch [3/5], Step [800/1875], Loss: 0.1483\n",
      "Epoch [3/5], Step [900/1875], Loss: 0.0787\n",
      "Epoch [3/5], Step [1000/1875], Loss: 0.0967\n",
      "Epoch [3/5], Step [1100/1875], Loss: 0.0200\n",
      "Epoch [3/5], Step [1200/1875], Loss: 0.1457\n",
      "Epoch [3/5], Step [1300/1875], Loss: 0.0767\n",
      "Epoch [3/5], Step [1400/1875], Loss: 0.0844\n",
      "Epoch [3/5], Step [1500/1875], Loss: 0.0510\n",
      "Epoch [3/5], Step [1600/1875], Loss: 0.1182\n",
      "Epoch [3/5], Step [1700/1875], Loss: 0.1350\n",
      "Epoch [3/5], Step [1800/1875], Loss: 0.1212\n",
      "Epoch [4/5], Step [100/1875], Loss: 0.0311\n",
      "Epoch [4/5], Step [200/1875], Loss: 0.0680\n",
      "Epoch [4/5], Step [300/1875], Loss: 0.0528\n",
      "Epoch [4/5], Step [400/1875], Loss: 0.0087\n",
      "Epoch [4/5], Step [500/1875], Loss: 0.0226\n",
      "Epoch [4/5], Step [600/1875], Loss: 0.0674\n",
      "Epoch [4/5], Step [700/1875], Loss: 0.0641\n",
      "Epoch [4/5], Step [800/1875], Loss: 0.0382\n",
      "Epoch [4/5], Step [900/1875], Loss: 0.0190\n",
      "Epoch [4/5], Step [1000/1875], Loss: 0.0612\n",
      "Epoch [4/5], Step [1100/1875], Loss: 0.1427\n",
      "Epoch [4/5], Step [1200/1875], Loss: 0.1168\n",
      "Epoch [4/5], Step [1300/1875], Loss: 0.2360\n",
      "Epoch [4/5], Step [1400/1875], Loss: 0.0474\n",
      "Epoch [4/5], Step [1500/1875], Loss: 0.0050\n",
      "Epoch [4/5], Step [1600/1875], Loss: 0.0365\n",
      "Epoch [4/5], Step [1700/1875], Loss: 0.0607\n",
      "Epoch [4/5], Step [1800/1875], Loss: 0.1184\n",
      "Epoch [5/5], Step [100/1875], Loss: 0.0681\n",
      "Epoch [5/5], Step [200/1875], Loss: 0.0124\n",
      "Epoch [5/5], Step [300/1875], Loss: 0.1696\n",
      "Epoch [5/5], Step [400/1875], Loss: 0.0044\n",
      "Epoch [5/5], Step [500/1875], Loss: 0.0640\n",
      "Epoch [5/5], Step [600/1875], Loss: 0.0499\n",
      "Epoch [5/5], Step [700/1875], Loss: 0.4094\n",
      "Epoch [5/5], Step [800/1875], Loss: 0.0092\n",
      "Epoch [5/5], Step [900/1875], Loss: 0.0048\n",
      "Epoch [5/5], Step [1000/1875], Loss: 0.0763\n",
      "Epoch [5/5], Step [1100/1875], Loss: 0.0180\n",
      "Epoch [5/5], Step [1200/1875], Loss: 0.0351\n",
      "Epoch [5/5], Step [1300/1875], Loss: 0.0215\n",
      "Epoch [5/5], Step [1400/1875], Loss: 0.1725\n",
      "Epoch [5/5], Step [1500/1875], Loss: 0.1057\n",
      "Epoch [5/5], Step [1600/1875], Loss: 0.0258\n",
      "Epoch [5/5], Step [1700/1875], Loss: 0.0118\n",
      "Epoch [5/5], Step [1800/1875], Loss: 0.2016\n",
      "Accuracy of the network on the 10000 test images: 97.18 %\n",
      "Flor wrote log records locally.\n"
     ]
    }
   ],
   "source": [
    "! python train.py --flor mySecondRun --hidden 75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced (Optional): Batch Processing\n",
    "Alternatively, we can call `flor.batch()` from an interactive environment\n",
    "inside our model training repository, to dispatch a group of jobs that can be long-runnning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--hidden 100 --lr 0.0001 \n",
      "--hidden 100 --lr 0.001 \n",
      "--hidden 200 --lr 0.0001 \n",
      "--hidden 200 --lr 0.001 \n",
      "--hidden 300 --lr 0.0001 \n",
      "--hidden 300 --lr 0.001 \n",
      "--hidden 400 --lr 0.0001 \n",
      "--hidden 400 --lr 0.001 \n",
      "--hidden 500 --lr 0.0001 \n",
      "--hidden 500 --lr 0.001 \n"
     ]
    }
   ],
   "source": [
    "import flor\n",
    "\n",
    "jobs = flor.cross_prod(hidden=[i*100 for i in range(1,6)],lr=(1e-4, 1e-3))\n",
    "assert jobs is not None\n",
    "\n",
    "flor.batch(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, using a new console or terminal, we start a `flordb` server to process the batch jobs:\n",
    "```bash\n",
    "$ python -m flor serve\n",
    "```\n",
    "\n",
    "or, if we want to allocate a GPU to the flor server:\n",
    "```bash\n",
    "$ python -m flor serve 0 \n",
    "```\n",
    "(where 0 is replaced by the GPU id).\n",
    "\n",
    "You can check the progress of your jobs with the following query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done|path|count(*)\n",
      "1|/home/rogarcia/git/ml_tutorial|10\n"
     ]
    }
   ],
   "source": [
    "!sqlite3 ~/.flor/main.db -header 'select done, path, count(*) from jobs group by done, path;'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, the query will report 10 jobs marked as `done` = 1\n",
    "\n",
    "```\n",
    "done|path|count(*)\n",
    "1|/Users/rogarcia/git/ml_tutorial|10\n",
    "```\n",
    "\n",
    "You can view the updated pivot view as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>projid</th>\n",
       "      <th>runid</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>vid</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>loss</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>hidden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>myFirstRun</td>\n",
       "      <td>2023-07-20T13:31:46</td>\n",
       "      <td>14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.17260010540485382</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>myFirstRun</td>\n",
       "      <td>2023-07-20T13:31:46</td>\n",
       "      <td>14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.46620410680770874</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>myFirstRun</td>\n",
       "      <td>2023-07-20T13:31:46</td>\n",
       "      <td>14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>0.14557793736457825</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>myFirstRun</td>\n",
       "      <td>2023-07-20T13:31:46</td>\n",
       "      <td>14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>0.10743971914052963</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>myFirstRun</td>\n",
       "      <td>2023-07-20T13:31:46</td>\n",
       "      <td>14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.23169249296188354</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           projid       runid               tstamp  \\\n",
       "0  ml_tutorial_flor.shadow.readme  myFirstRun  2023-07-20T13:31:46   \n",
       "1  ml_tutorial_flor.shadow.readme  myFirstRun  2023-07-20T13:31:46   \n",
       "2  ml_tutorial_flor.shadow.readme  myFirstRun  2023-07-20T13:31:46   \n",
       "3  ml_tutorial_flor.shadow.readme  myFirstRun  2023-07-20T13:31:46   \n",
       "4  ml_tutorial_flor.shadow.readme  myFirstRun  2023-07-20T13:31:46   \n",
       "\n",
       "                                        vid  epoch  step                 loss  \\\n",
       "0  14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1      1   100  0.17260010540485382   \n",
       "1  14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1      1   200  0.46620410680770874   \n",
       "2  14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1      1   300  0.14557793736457825   \n",
       "3  14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1      1   400  0.10743971914052963   \n",
       "4  14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1      1   500  0.23169249296188354   \n",
       "\n",
       "  epochs batch_size     lr hidden  \n",
       "0      5         32  0.001    500  \n",
       "1      5         32  0.001    500  \n",
       "2      5         32  0.001    500  \n",
       "3      5         32  0.001    500  \n",
       "4      5         32  0.001    500  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = full_pivot(log_records())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vid'].drop_duplicates().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Traing Kit (MTK)\n",
    "The Model Training Kit (MTK) includes utilities for serializing and checkpointing PyTorch state,\n",
    "and utilities for resuming, auto-parallelizing, and memoizing executions from checkpoint.\n",
    "\n",
    "In this context, `Flor` is an alias for `MTK`. The model developer passes objects for checkpointing to `Flor.checkpoints(*args)`,\n",
    "and gives it control over loop iterators by \n",
    "calling `Flor.loop(iterator)` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion = nn.CrossEntropyLoss()\n",
      "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
      "\n",
      "Flor.checkpoints(model, optimizer)\n",
      "\n",
      "# Train the model\n",
      "total_step = len(train_loader)\n",
      "for epoch in Flor.loop(range(num_epochs)):\n",
      "    for i, (images, labels) in Flor.loop(enumerate(train_loader)):\n",
      "        # Move tensors to the configured device\n",
      "        images = images.reshape(-1, 28 * 28).to(device)\n",
      "        labels = labels.to(device)\n",
      "\n",
      "        # Forward pass\n",
      "        outputs = model(images)\n",
      "        loss = criterion(outputs, labels)\n",
      "\n",
      "        # Backward and optimize\n",
      "        optimizer.zero_grad()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "\n",
      "        if (i + 1) % 100 == 0:\n",
      "            print(\n",
      "                \"Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}\".format(\n",
      "                    epoch + 1,\n",
      "                    num_epochs,\n",
      "                    i + 1,\n",
      "                    total_step,\n"
     ]
    }
   ],
   "source": [
    "!cat train.py | grep -B 3 -A 25 Flor.checkpoints "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown, \n",
    "we wrap both the nested training loop and main loop with `Flor.loop` so Flor can manage their state. Flor will use loop iteration boundaries to store selected checkpoints adaptively, and on replay time use those same checkpoints to resume training from the appropriate epoch.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging API\n",
    "\n",
    "You call `flor.log(name, value)` and `flor.arg(name, default=None)` to log metrics and register tune-able hyper-parameters, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_size = flor.arg(\"hidden\", default=500)\n",
      "num_epochs = flor.arg(\"epochs\", 5)\n",
      "batch_size = flor.arg(\"batch_size\", 32)\n",
      "learning_rate = flor.arg(\"lr\", 1e-3)\n"
     ]
    }
   ],
   "source": [
    "%cat train.py | grep flor.arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    num_epochs,\n",
      "                    i + 1,\n",
      "                    total_step,\n",
      "                    flor.log(\"loss\", loss.item()),\n",
      "                )\n",
      "            )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%cat train.py | grep -C 3 flor.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `name`(s) you use for the variables you intercept with `flor.log` and `flor.arg` will become a column (measure) in the full pivoted view (see [Viewing your exp history](#view-your-experiment-history)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storage & Data Layout\n",
    "On each run, Flor will:\n",
    "1. Save model checkpoints in `~/.flor/`\n",
    "1. Commit code changes, command-line args, and log records to `git`, inside a dedicated `flor.shadow` branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 rogarcia  20K Jul 20 13:38 main.db\n",
      "-rw-r--r--  1 rogarcia 176K Jul 20 13:40 ml_tutorial.db\n",
      "drwxrwxr-x  5 rogarcia 4.0K Jul 20 13:40 ml_tutorial_flor.shadow.readme\n"
     ]
    }
   ],
   "source": [
    "! ls -lagh ~/.flor | grep \"ml_tutorial\\|main\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rogarcia/git/ml_tutorial\n",
      "* \u001b[32mflor.shadow.readme\u001b[m\n"
     ]
    }
   ],
   "source": [
    "! echo $(pwd)\n",
    "! git branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rogarcia/git/ml_tutorial/.flor\n",
      "total 20K\n",
      "drwxrwxr-x 2 rogarcia 4.0K Jul 20 13:40 .\n",
      "drwxrwxr-x 4 rogarcia 4.0K Jul 20 13:31 ..\n",
      "-rw-rw-r-- 1 rogarcia 2.9K Jul 20 13:40 log_records.csv\n",
      "-rw-rw-r-- 1 rogarcia  236 Jul 20 13:40 .replay.json\n",
      "-rw-rw-r-- 1 rogarcia  223 Jul 20 13:40 seconds.json\n"
     ]
    }
   ],
   "source": [
    "! echo $(pwd)'/.flor'\n",
    "! ls -lagh ./.flor/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flor will access and interpret contents of `.flor` automatically. The data and log records will be exposed to the user via SQL or Pandas queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hindsight Logging\n",
    "\n",
    "\n",
    "Suppose you wanted to start logging the `device`\n",
    "identifier where the model is run, as well as the\n",
    "final `accuracy` after training.\n",
    "You would add the corresponding logging statements\n",
    "to `train.py`, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from flor import MTK as Flor\n",
      "\n",
      "# Device configuration\n",
      "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
      "flor.log(\"device\", str(device))\n",
      "\n",
      "# Hyper-parameters\n",
      "input_size = 784\n",
      "hidden_size = flor.arg(\"hidden\", default=500)\n",
      "--\n",
      "                    epoch + 1,\n",
      "                    num_epochs,\n",
      "                    i + 1,\n",
      "                    total_step,\n",
      "                    flor.log(\"loss\", loss.item()),\n",
      "                )\n",
      "            )\n",
      "\n",
      "# Test the model\n",
      "--\n",
      "        correct += (predicted == labels).sum().item()\n",
      "\n",
      "    print(\n",
      "        \"Accuracy of the network on the 10000 test images: {} %\".format(\n",
      "            flor.log(\"accuracy\", 100 * correct / total)\n",
      "        )\n",
      "    )\n"
     ]
    }
   ],
   "source": [
    "%cat train.py | grep -C 4 flor.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rogarcia/git/ml_tutorial\n",
      "LICENSE notebook.ipynb README.md train.py flor.shadow.readme\n",
      "[flor.shadow.readme 04b7174] hindsight logging stmts added.\n",
      " 1 file changed, 2 insertions(+), 1 deletion(-)\n"
     ]
    }
   ],
   "source": [
    "! echo $(pwd)\n",
    "! git commit -am \"hindsight logging stmts added.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, when you add a logging statement, logging \n",
    "begins \"from now on\", and you have no visibility into the past.\n",
    "With hindsight logging, the aim is to allow model developers to send\n",
    "new logging statements back in time, and replay the past \n",
    "efficiently from checkpoint.\n",
    "\n",
    "In order to do that, we open up an interactive environent from within the `ml_tutorial` directory, and call `flor.replay()`, asking flor to apply the logging statements with the names `device` and `accuracy` to all previous versions (leave `where_clause` null in `flor.replay()`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What is the log level of logging statement `device`? Leave blank to infer `DATA_PREP`:  \n",
      "What is the log level of logging statement `accuracy`? Leave blank to infer `DATA_PREP`:  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>projid</th>\n",
       "      <th>runid</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>vid</th>\n",
       "      <th>prep_secs</th>\n",
       "      <th>eval_secs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>myFirstRun</td>\n",
       "      <td>2023-07-20T13:31:46</td>\n",
       "      <td>14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1</td>\n",
       "      <td>2.418149</td>\n",
       "      <td>0.571114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>mySecondRun</td>\n",
       "      <td>2023-07-20T13:33:30</td>\n",
       "      <td>2be1ef88e7b2e39d2a5844b0945811244bb40715</td>\n",
       "      <td>0.680741</td>\n",
       "      <td>0.561131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>BATCH</td>\n",
       "      <td>2023-07-20T13:34:24</td>\n",
       "      <td>d1035feb1274889a9f479f3f687659fc7bf712b8</td>\n",
       "      <td>0.679419</td>\n",
       "      <td>0.555125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>BATCH</td>\n",
       "      <td>2023-07-20T13:34:50</td>\n",
       "      <td>4d1d90fa76b932edd2d637c0adfce8979487824f</td>\n",
       "      <td>0.681324</td>\n",
       "      <td>0.558446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>BATCH</td>\n",
       "      <td>2023-07-20T13:35:15</td>\n",
       "      <td>60598fc693c15877a912366b2e29b6f35158a1e1</td>\n",
       "      <td>0.669353</td>\n",
       "      <td>0.560964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>BATCH</td>\n",
       "      <td>2023-07-20T13:35:40</td>\n",
       "      <td>ef946c517a019861e7f7cf13b956deea3f3e0978</td>\n",
       "      <td>0.652545</td>\n",
       "      <td>0.559790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>BATCH</td>\n",
       "      <td>2023-07-20T13:36:05</td>\n",
       "      <td>8e34cf572b8ea2f3fcfd8b7e398702a5023b8d0c</td>\n",
       "      <td>0.658422</td>\n",
       "      <td>0.559380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>BATCH</td>\n",
       "      <td>2023-07-20T13:36:30</td>\n",
       "      <td>35f276660121be3b166da84f8808c41236dff6dd</td>\n",
       "      <td>0.670165</td>\n",
       "      <td>0.563717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>BATCH</td>\n",
       "      <td>2023-07-20T13:36:56</td>\n",
       "      <td>cdc3c10f280e3473cb47f49425aa1d7db78fff42</td>\n",
       "      <td>0.659957</td>\n",
       "      <td>0.565566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>BATCH</td>\n",
       "      <td>2023-07-20T13:37:22</td>\n",
       "      <td>5e53085992c1ed7941fe26930859cb4f86cba40c</td>\n",
       "      <td>0.681741</td>\n",
       "      <td>0.564458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>BATCH</td>\n",
       "      <td>2023-07-20T13:37:47</td>\n",
       "      <td>ada7233fb518dec337d3d0cb0db30cbb6ffea89a</td>\n",
       "      <td>0.665637</td>\n",
       "      <td>0.563041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>BATCH</td>\n",
       "      <td>2023-07-20T13:38:13</td>\n",
       "      <td>b4a67ec7b137c11b49ad029986ebdfd877d8a20f</td>\n",
       "      <td>0.667281</td>\n",
       "      <td>0.553334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            projid        runid               tstamp  \\\n",
       "0   ml_tutorial_flor.shadow.readme   myFirstRun  2023-07-20T13:31:46   \n",
       "1   ml_tutorial_flor.shadow.readme  mySecondRun  2023-07-20T13:33:30   \n",
       "2   ml_tutorial_flor.shadow.readme        BATCH  2023-07-20T13:34:24   \n",
       "3   ml_tutorial_flor.shadow.readme        BATCH  2023-07-20T13:34:50   \n",
       "4   ml_tutorial_flor.shadow.readme        BATCH  2023-07-20T13:35:15   \n",
       "5   ml_tutorial_flor.shadow.readme        BATCH  2023-07-20T13:35:40   \n",
       "6   ml_tutorial_flor.shadow.readme        BATCH  2023-07-20T13:36:05   \n",
       "7   ml_tutorial_flor.shadow.readme        BATCH  2023-07-20T13:36:30   \n",
       "8   ml_tutorial_flor.shadow.readme        BATCH  2023-07-20T13:36:56   \n",
       "9   ml_tutorial_flor.shadow.readme        BATCH  2023-07-20T13:37:22   \n",
       "10  ml_tutorial_flor.shadow.readme        BATCH  2023-07-20T13:37:47   \n",
       "11  ml_tutorial_flor.shadow.readme        BATCH  2023-07-20T13:38:13   \n",
       "\n",
       "                                         vid  prep_secs  eval_secs  \n",
       "0   14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1   2.418149   0.571114  \n",
       "1   2be1ef88e7b2e39d2a5844b0945811244bb40715   0.680741   0.561131  \n",
       "2   d1035feb1274889a9f479f3f687659fc7bf712b8   0.679419   0.555125  \n",
       "3   4d1d90fa76b932edd2d637c0adfce8979487824f   0.681324   0.558446  \n",
       "4   60598fc693c15877a912366b2e29b6f35158a1e1   0.669353   0.560964  \n",
       "5   ef946c517a019861e7f7cf13b956deea3f3e0978   0.652545   0.559790  \n",
       "6   8e34cf572b8ea2f3fcfd8b7e398702a5023b8d0c   0.658422   0.559380  \n",
       "7   35f276660121be3b166da84f8808c41236dff6dd   0.670165   0.563717  \n",
       "8   cdc3c10f280e3473cb47f49425aa1d7db78fff42   0.659957   0.565566  \n",
       "9   5e53085992c1ed7941fe26930859cb4f86cba40c   0.681741   0.564458  \n",
       "10  ada7233fb518dec337d3d0cb0db30cbb6ffea89a   0.665637   0.563041  \n",
       "11  b4a67ec7b137c11b49ad029986ebdfd877d8a20f   0.667281   0.553334  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Continue replaying 12 versions at DATA_PREP level for 52.52 seconds?[Y/n]?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flordb registered 12 replay jobs.\n"
     ]
    }
   ],
   "source": [
    "flor.replay(['device', 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, using a new console or terminal, we start a `flordb` server to process the batch jobs:\n",
    "```bash\n",
    "$ python -m flor serve\n",
    "```\n",
    "\n",
    "or, if we want to allocate a GPU to the flor server:\n",
    "```bash\n",
    "$ python -m flor serve 0 \n",
    "```\n",
    "(where 0 is replaced by the GPU id).\n",
    "\n",
    "You can check the progress of your jobs with the following query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done|path|appvars|count(*)\n",
      "1|/home/rogarcia/git/ml_tutorial|device, accuracy|12\n"
     ]
    }
   ],
   "source": [
    "!sqlite3 ~/.flor/main.db -header 'select done, path, appvars, count(*) from replay group by done, path, appvars;'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the process is finished, you will be able to view the values for `device` and `accuracy` for historical executions, and they will continue to be logged in subsequent iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>projid</th>\n",
       "      <th>runid</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>vid</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>loss</th>\n",
       "      <th>device</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>hidden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>myFirstRun</td>\n",
       "      <td>2023-07-20T13:31:46</td>\n",
       "      <td>14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.17260010540485382</td>\n",
       "      <td>cuda</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>97.88</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>myFirstRun</td>\n",
       "      <td>2023-07-20T13:31:46</td>\n",
       "      <td>14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.46620410680770874</td>\n",
       "      <td>cuda</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>97.88</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>myFirstRun</td>\n",
       "      <td>2023-07-20T13:31:46</td>\n",
       "      <td>14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>0.14557793736457825</td>\n",
       "      <td>cuda</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>97.88</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>myFirstRun</td>\n",
       "      <td>2023-07-20T13:31:46</td>\n",
       "      <td>14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>0.10743971914052963</td>\n",
       "      <td>cuda</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>97.88</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>myFirstRun</td>\n",
       "      <td>2023-07-20T13:31:46</td>\n",
       "      <td>14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.23169249296188354</td>\n",
       "      <td>cuda</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>97.88</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           projid       runid               tstamp  \\\n",
       "0  ml_tutorial_flor.shadow.readme  myFirstRun  2023-07-20T13:31:46   \n",
       "1  ml_tutorial_flor.shadow.readme  myFirstRun  2023-07-20T13:31:46   \n",
       "2  ml_tutorial_flor.shadow.readme  myFirstRun  2023-07-20T13:31:46   \n",
       "3  ml_tutorial_flor.shadow.readme  myFirstRun  2023-07-20T13:31:46   \n",
       "4  ml_tutorial_flor.shadow.readme  myFirstRun  2023-07-20T13:31:46   \n",
       "\n",
       "                                        vid  epoch  step                 loss  \\\n",
       "0  14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1      1   100  0.17260010540485382   \n",
       "1  14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1      1   200  0.46620410680770874   \n",
       "2  14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1      1   300  0.14557793736457825   \n",
       "3  14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1      1   400  0.10743971914052963   \n",
       "4  14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1      1   500  0.23169249296188354   \n",
       "\n",
       "  device epochs batch_size     lr accuracy hidden  \n",
       "0   cuda      5         32  0.001    97.88    500  \n",
       "1   cuda      5         32  0.001    97.88    500  \n",
       "2   cuda      5         32  0.001    97.88    500  \n",
       "3   cuda      5         32  0.001    97.88    500  \n",
       "4   cuda      5         32  0.001    97.88    500  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flor import full_pivot, log_records\n",
    "df = full_pivot(log_records())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>projid</th>\n",
       "      <th>runid</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>vid</th>\n",
       "      <th>device</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>myFirstRun</td>\n",
       "      <td>2023-07-20T13:31:46</td>\n",
       "      <td>14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>97.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>mySecondRun</td>\n",
       "      <td>2023-07-20T13:33:30</td>\n",
       "      <td>2be1ef88e7b2e39d2a5844b0945811244bb40715</td>\n",
       "      <td>cuda</td>\n",
       "      <td>97.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>BATCH</td>\n",
       "      <td>2023-07-20T13:34:24</td>\n",
       "      <td>d1035feb1274889a9f479f3f687659fc7bf712b8</td>\n",
       "      <td>cuda</td>\n",
       "      <td>93.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>BATCH</td>\n",
       "      <td>2023-07-20T13:34:50</td>\n",
       "      <td>4d1d90fa76b932edd2d637c0adfce8979487824f</td>\n",
       "      <td>cuda</td>\n",
       "      <td>97.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>BATCH</td>\n",
       "      <td>2023-07-20T13:35:15</td>\n",
       "      <td>60598fc693c15877a912366b2e29b6f35158a1e1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>94.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>BATCH</td>\n",
       "      <td>2023-07-20T13:35:40</td>\n",
       "      <td>ef946c517a019861e7f7cf13b956deea3f3e0978</td>\n",
       "      <td>cuda</td>\n",
       "      <td>97.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>BATCH</td>\n",
       "      <td>2023-07-20T13:36:05</td>\n",
       "      <td>8e34cf572b8ea2f3fcfd8b7e398702a5023b8d0c</td>\n",
       "      <td>cuda</td>\n",
       "      <td>95.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>BATCH</td>\n",
       "      <td>2023-07-20T13:36:30</td>\n",
       "      <td>35f276660121be3b166da84f8808c41236dff6dd</td>\n",
       "      <td>cuda</td>\n",
       "      <td>97.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>BATCH</td>\n",
       "      <td>2023-07-20T13:36:56</td>\n",
       "      <td>cdc3c10f280e3473cb47f49425aa1d7db78fff42</td>\n",
       "      <td>cuda</td>\n",
       "      <td>95.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>BATCH</td>\n",
       "      <td>2023-07-20T13:37:22</td>\n",
       "      <td>5e53085992c1ed7941fe26930859cb4f86cba40c</td>\n",
       "      <td>cuda</td>\n",
       "      <td>97.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>BATCH</td>\n",
       "      <td>2023-07-20T13:37:47</td>\n",
       "      <td>ada7233fb518dec337d3d0cb0db30cbb6ffea89a</td>\n",
       "      <td>cuda</td>\n",
       "      <td>96.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>ml_tutorial_flor.shadow.readme</td>\n",
       "      <td>BATCH</td>\n",
       "      <td>2023-07-20T13:38:13</td>\n",
       "      <td>b4a67ec7b137c11b49ad029986ebdfd877d8a20f</td>\n",
       "      <td>cuda</td>\n",
       "      <td>98.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             projid        runid               tstamp  \\\n",
       "0    ml_tutorial_flor.shadow.readme   myFirstRun  2023-07-20T13:31:46   \n",
       "90   ml_tutorial_flor.shadow.readme  mySecondRun  2023-07-20T13:33:30   \n",
       "180  ml_tutorial_flor.shadow.readme        BATCH  2023-07-20T13:34:24   \n",
       "270  ml_tutorial_flor.shadow.readme        BATCH  2023-07-20T13:34:50   \n",
       "360  ml_tutorial_flor.shadow.readme        BATCH  2023-07-20T13:35:15   \n",
       "450  ml_tutorial_flor.shadow.readme        BATCH  2023-07-20T13:35:40   \n",
       "540  ml_tutorial_flor.shadow.readme        BATCH  2023-07-20T13:36:05   \n",
       "630  ml_tutorial_flor.shadow.readme        BATCH  2023-07-20T13:36:30   \n",
       "720  ml_tutorial_flor.shadow.readme        BATCH  2023-07-20T13:36:56   \n",
       "810  ml_tutorial_flor.shadow.readme        BATCH  2023-07-20T13:37:22   \n",
       "900  ml_tutorial_flor.shadow.readme        BATCH  2023-07-20T13:37:47   \n",
       "990  ml_tutorial_flor.shadow.readme        BATCH  2023-07-20T13:38:13   \n",
       "\n",
       "                                          vid device accuracy  \n",
       "0    14480b3c1ec4636e0f26ec51b5bc7bc1a5c7d9d1   cuda    97.88  \n",
       "90   2be1ef88e7b2e39d2a5844b0945811244bb40715   cuda    97.18  \n",
       "180  d1035feb1274889a9f479f3f687659fc7bf712b8   cuda    93.83  \n",
       "270  4d1d90fa76b932edd2d637c0adfce8979487824f   cuda    97.57  \n",
       "360  60598fc693c15877a912366b2e29b6f35158a1e1   cuda    94.69  \n",
       "450  ef946c517a019861e7f7cf13b956deea3f3e0978   cuda    97.43  \n",
       "540  8e34cf572b8ea2f3fcfd8b7e398702a5023b8d0c   cuda    95.43  \n",
       "630  35f276660121be3b166da84f8808c41236dff6dd   cuda    97.63  \n",
       "720  cdc3c10f280e3473cb47f49425aa1d7db78fff42   cuda    95.92  \n",
       "810  5e53085992c1ed7941fe26930859cb4f86cba40c   cuda    97.81  \n",
       "900  ada7233fb518dec337d3d0cb0db30cbb6ffea89a   cuda    96.15  \n",
       "990  b4a67ec7b137c11b49ad029986ebdfd877d8a20f   cuda    98.03  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[list(flor.DATA_PREP) + ['device', 'accuracy']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the new columns `device` and `accuracy` that are backfilled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publications\n",
    "\n",
    "To cite this work, please refer to the [Hindsight Logging](http://www.vldb.org/pvldb/vol14/p682-garcia.pdf) paper (VLDB '21).\n",
    "\n",
    "FLOR is open source software developed at UC Berkeley. \n",
    "[Joe Hellerstein](https://dsf.berkeley.edu/jmh/) (databases), [Joey Gonzalez](http://people.eecs.berkeley.edu/~jegonzal/) (machine learning), and [Koushik Sen](https://people.eecs.berkeley.edu/~ksen) (programming languages) \n",
    "are the primary faculty members leading this work.\n",
    "\n",
    "This work is released as part of [Rolando Garcia](https://rlnsanz.github.io/)'s doctoral dissertation at UC Berkeley,\n",
    "and has been the subject of study by Eric Liu and Anusha Dandamudi, \n",
    "both of whom completed their master's theses on FLOR.\n",
    "Our list of publications are reproduced below.\n",
    "Finally, we thank [Vikram Sreekanti](https://www.vikrams.io/), [Dan Crankshaw](https://dancrankshaw.com/), and [Neeraja Yadwadkar](https://cs.stanford.edu/~neeraja/) for guidance, comments, and advice.\n",
    "[Bobby Yan](https://bobbyy.org/) was instrumental in the development of FLOR and its corresponding experimental evaluation.\n",
    "\n",
    "* [Hindsight Logging for Model Training](http://www.vldb.org/pvldb/vol14/p682-garcia.pdf). _R Garcia, E Liu, V Sreekanti, B Yan, A Dandamudi, JE Gonzalez, JM Hellerstein, K Sen_. The VLDB Journal, 2021.\n",
    "* [Fast Low-Overhead Logging Extending Time](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2021/EECS-2021-117.html). _A Dandamudi_. EECS Department, UC Berkeley Technical Report, 2021.\n",
    "* [Low Overhead Materialization with FLOR](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2020/EECS-2020-79.html). _E Liu_. EECS Department, UC Berkeley Technical Report, 2020. \n",
    "\n",
    "\n",
    "## License\n",
    "FLOR is licensed under the [Apache v2 License](https://www.apache.org/licenses/LICENSE-2.0).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
