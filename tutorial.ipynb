{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install flordb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "We start by selecting (or creating) a `git` repository to save our model training code as we iterate and experiment. Flor automatically commits your changes on every run, so no change is lost. Below we provide a sample repository you can use to follow along:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "!git clone git@github.com:ucbepic/ml_tutorial ../ml_tutorial\n",
    "os.chdir('../ml_tutorial/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the `train.py` script to train a small linear model, \n",
    "and test your `flordb` installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! python train.py --flor myFirstRun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flor will manage checkpoints, logs, command-line arguments, code changes, and other experiment metadata on each run (More details [below](#storage--data-layout)). All of this data is then expesed to the user via SQL or Pandas queries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View your experiment history\n",
    "From the same directory you ran the examples above, open an iPython terminal, then load and pivot the log records.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flor import full_pivot, log_records\n",
    "df = full_pivot(log_records())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run some more experiments\n",
    "The `train.py` script has been prepared in advance to define and manage four different hyper-parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat train.py | grep flor.arg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can control any of the hyper-parameters (e.g. `hidden`) using Flor's command-line interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python train.py --flor mySecondRun --hidden 75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced (Optional): Batch Processing\n",
    "Alternatively, we can call `flor.batch()` from an interactive environment\n",
    "inside our model training repository, to dispatch a group of jobs that can be long-runnning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flor\n",
    "\n",
    "jobs = flor.cross_prod(hidden=[i*100 for i in range(1,6)],lr=(1e-4, 1e-3))\n",
    "assert jobs is not None\n",
    "\n",
    "flor.batch(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, using a new console or terminal, we start a `flordb` server to process the batch jobs:\n",
    "```bash\n",
    "$ python -m flor serve\n",
    "```\n",
    "\n",
    "or, if we want to allocate a GPU to the flor server:\n",
    "```bash\n",
    "$ python -m flor serve 0 \n",
    "```\n",
    "(where 0 is replaced by the GPU id).\n",
    "\n",
    "You can check the progress of your jobs with the following query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sqlite3 ~/.flor/main.db -header 'select done, path, count(*) from jobs group by done, path;'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, the query will report 10 jobs marked as `done` = 1\n",
    "\n",
    "```\n",
    "done|path|count(*)\n",
    "1|/Users/rogarcia/git/ml_tutorial|10\n",
    "```\n",
    "\n",
    "You can view the updated pivot view as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = full_pivot(log_records())\n",
    "\n",
    "print(df['vid'].drop_duplicates().count(), 'versions')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Traing Kit (MTK)\n",
    "The Model Training Kit (MTK) includes utilities for serializing and checkpointing PyTorch state,\n",
    "and utilities for resuming, auto-parallelizing, and memoizing executions from checkpoint.\n",
    "\n",
    "In this context, `Flor` is an alias for `MTK`. The model developer passes objects for checkpointing to `Flor.checkpoints(*args)`,\n",
    "and gives it control over loop iterators by \n",
    "calling `Flor.loop(iterator)` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat train.py | grep -B 3 -A 25 Flor.checkpoints "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown, \n",
    "we wrap both the nested training loop and main loop with `Flor.loop` so Flor can manage their state. Flor will use loop iteration boundaries to store selected checkpoints adaptively, and on replay time use those same checkpoints to resume training from the appropriate epoch.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging API\n",
    "\n",
    "You call `flor.log(name, value)` and `flor.arg(name, default=None)` to log metrics and register tune-able hyper-parameters, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat train.py | grep -C 3 -e 'flor.arg' -e 'flor.log'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `name`(s) you use for the variables you intercept with `flor.log` and `flor.arg` will become a column (measure) in the full pivoted view (see [Viewing your exp history](#view-your-experiment-history)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hindsight Logging\n",
    "\n",
    "\n",
    "Suppose you wanted to start logging the `device`\n",
    "identifier where the model is run, as well as the\n",
    "final `accuracy` after training.\n",
    "You would add the corresponding logging statements\n",
    "to `train.py`, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat train.py | grep -C 4 flor.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo $(pwd)\n",
    "! git commit -am \"hindsight logging stmts added.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, when you add a logging statement, logging \n",
    "begins \"from now on\", and you have no visibility into the past.\n",
    "With hindsight logging, the aim is to allow model developers to send\n",
    "new logging statements back in time, and replay the past \n",
    "efficiently from checkpoint.\n",
    "\n",
    "In order to do that, we open up an interactive environent from within the `ml_tutorial` directory, and call `flor.replay()`, asking flor to apply the logging statements with the names `device` and `accuracy` to all previous versions (leave `where_clause` null in `flor.replay()`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flor.replay(['device', 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, using a new console or terminal, we start a `flordb` server to process the batch jobs:\n",
    "```bash\n",
    "$ python -m flor serve\n",
    "```\n",
    "\n",
    "or, if we want to allocate a GPU to the flor server:\n",
    "```bash\n",
    "$ python -m flor serve 0 \n",
    "```\n",
    "(where 0 is replaced by the GPU id).\n",
    "\n",
    "You can check the progress of your jobs with the following query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sqlite3 ~/.flor/main.db -header 'select done, path, appvars, count(*) from replay group by done, path, appvars;'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the process is finished, you will be able to view the values for `device` and `accuracy` for historical executions, and they will continue to be logged in subsequent iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flor import full_pivot, log_records\n",
    "df = full_pivot(log_records())\n",
    "df[list(flor.DATA_PREP) + ['device', 'accuracy']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the new columns `device` and `accuracy` that are backfilled."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
