{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install flordb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "We start by selecting (or creating) a `git` repository to save our model training code as we iterate and experiment. Flor automatically commits your changes on every run, so no change is lost. Below we provide a sample repository you can use to follow along:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "!git clone git@github.com:ucbepic/ml_tutorial ../ml_tutorial\n",
    "os.chdir('../ml_tutorial/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the `train.py` script to train a small linear model, \n",
    "and test your `flordb` installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! python train.py --flor myFirstRun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flor will manage checkpoints, logs, command-line arguments, code changes, and other experiment metadata on each run (More details [below](#storage--data-layout)). All of this data is then expesed to the user via SQL or Pandas queries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View your experiment history\n",
    "From the same directory you ran the examples above, open an iPython terminal, then load and pivot the log records.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flor import full_pivot, log_records\n",
    "df = full_pivot(log_records())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run some more experiments\n",
    "The `train.py` script has been prepared in advance to define and manage four different hyper-parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat train.py | grep flor.arg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can control any of the hyper-parameters (e.g. `hidden`) using Flor's command-line interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python train.py --flor mySecondRun --hidden 75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced (Optional): Batch Processing\n",
    "Alternatively, we can call `flor.batch()` from an interactive environment\n",
    "inside our model training repository, to dispatch a group of jobs that can be long-runnning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flor\n",
    "\n",
    "jobs = flor.cross_prod(hidden=[i*100 for i in range(1,6)],lr=(1e-4, 1e-3))\n",
    "assert jobs is not None\n",
    "\n",
    "flor.batch(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, using a new console or terminal, we start a `flordb` server to process the batch jobs:\n",
    "```bash\n",
    "$ python -m flor serve\n",
    "```\n",
    "\n",
    "or, if we want to allocate a GPU to the flor server:\n",
    "```bash\n",
    "$ python -m flor serve 0 \n",
    "```\n",
    "(where 0 is replaced by the GPU id).\n",
    "\n",
    "You can check the progress of your jobs with the following query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sqlite3 ~/.flor/main.db -header 'select done, path, count(*) from jobs group by done, path;'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, the query will report 10 jobs marked as `done` = 1\n",
    "\n",
    "```\n",
    "done|path|count(*)\n",
    "1|/Users/rogarcia/git/ml_tutorial|10\n",
    "```\n",
    "\n",
    "You can view the updated pivot view as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = full_pivot(log_records())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Traing Kit (MTK)\n",
    "The Model Training Kit (MTK) includes utilities for serializing and checkpointing PyTorch state,\n",
    "and utilities for resuming, auto-parallelizing, and memoizing executions from checkpoint.\n",
    "\n",
    "In this context, `Flor` is an alias for `MTK`. The model developer passes objects for checkpointing to `Flor.checkpoints(*args)`,\n",
    "and gives it control over loop iterators by \n",
    "calling `Flor.loop(iterator)` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat train.py | grep -B 3 -A 25 Flor.checkpoints "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown, \n",
    "we wrap both the nested training loop and main loop with `Flor.loop` so Flor can manage their state. Flor will use loop iteration boundaries to store selected checkpoints adaptively, and on replay time use those same checkpoints to resume training from the appropriate epoch.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging API\n",
    "\n",
    "You call `flor.log(name, value)` and `flor.arg(name, default=None)` to log metrics and register tune-able hyper-parameters, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat train.py | grep flor.arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat train.py | grep -C 3 flor.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `name`(s) you use for the variables you intercept with `flor.log` and `flor.arg` will become a column (measure) in the full pivoted view (see [Viewing your exp history](#view-your-experiment-history)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storage & Data Layout\n",
    "On each run, Flor will:\n",
    "1. Save model checkpoints in `~/.flor/`\n",
    "1. Commit code changes, command-line args, and log records to `git`, inside a dedicated `flor.shadow` branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -lagh ~/.flor | grep \"ml_tutorial\\|main\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo $(pwd)\n",
    "! git branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo $(pwd)'/.flor'\n",
    "! ls -lagh ./.flor/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flor will access and interpret contents of `.flor` automatically. The data and log records will be exposed to the user via SQL or Pandas queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hindsight Logging\n",
    "\n",
    "\n",
    "Suppose you wanted to start logging the `device`\n",
    "identifier where the model is run, as well as the\n",
    "final `accuracy` after training.\n",
    "You would add the corresponding logging statements\n",
    "to `train.py`, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat train.py | grep -C 4 flor.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo $(pwd)\n",
    "! git commit -am \"hindsight logging stmts added.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, when you add a logging statement, logging \n",
    "begins \"from now on\", and you have no visibility into the past.\n",
    "With hindsight logging, the aim is to allow model developers to send\n",
    "new logging statements back in time, and replay the past \n",
    "efficiently from checkpoint.\n",
    "\n",
    "In order to do that, we open up an interactive environent from within the `ml_tutorial` directory, and call `flor.replay()`, asking flor to apply the logging statements with the names `device` and `accuracy` to all previous versions (leave `where_clause` null in `flor.replay()`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flor.replay(['device', 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, using a new console or terminal, we start a `flordb` server to process the batch jobs:\n",
    "```bash\n",
    "$ python -m flor serve\n",
    "```\n",
    "\n",
    "or, if we want to allocate a GPU to the flor server:\n",
    "```bash\n",
    "$ python -m flor serve 0 \n",
    "```\n",
    "(where 0 is replaced by the GPU id).\n",
    "\n",
    "You can check the progress of your jobs with the following query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sqlite3 ~/.flor/main.db -header 'select done, path, appvars, count(*) from replay group by done, path, appvars;'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the process is finished, you will be able to view the values for `device` and `accuracy` for historical executions, and they will continue to be logged in subsequent iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flor import full_pivot, log_records\n",
    "df = full_pivot(log_records())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[list(flor.DATA_PREP) + ['device', 'accuracy']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the new columns `device` and `accuracy` that are backfilled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publications\n",
    "\n",
    "To cite this work, please refer to the [Hindsight Logging](http://www.vldb.org/pvldb/vol14/p682-garcia.pdf) paper (VLDB '21).\n",
    "\n",
    "FLOR is open source software developed at UC Berkeley. \n",
    "[Joe Hellerstein](https://dsf.berkeley.edu/jmh/) (databases), [Joey Gonzalez](http://people.eecs.berkeley.edu/~jegonzal/) (machine learning), and [Koushik Sen](https://people.eecs.berkeley.edu/~ksen) (programming languages) \n",
    "are the primary faculty members leading this work.\n",
    "\n",
    "This work is released as part of [Rolando Garcia](https://rlnsanz.github.io/)'s doctoral dissertation at UC Berkeley,\n",
    "and has been the subject of study by Eric Liu and Anusha Dandamudi, \n",
    "both of whom completed their master's theses on FLOR.\n",
    "Our list of publications are reproduced below.\n",
    "Finally, we thank [Vikram Sreekanti](https://www.vikrams.io/), [Dan Crankshaw](https://dancrankshaw.com/), and [Neeraja Yadwadkar](https://cs.stanford.edu/~neeraja/) for guidance, comments, and advice.\n",
    "[Bobby Yan](https://bobbyy.org/) was instrumental in the development of FLOR and its corresponding experimental evaluation.\n",
    "\n",
    "* [Hindsight Logging for Model Training](http://www.vldb.org/pvldb/vol14/p682-garcia.pdf). _R Garcia, E Liu, V Sreekanti, B Yan, A Dandamudi, JE Gonzalez, JM Hellerstein, K Sen_. The VLDB Journal, 2021.\n",
    "* [Fast Low-Overhead Logging Extending Time](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2021/EECS-2021-117.html). _A Dandamudi_. EECS Department, UC Berkeley Technical Report, 2021.\n",
    "* [Low Overhead Materialization with FLOR](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2020/EECS-2020-79.html). _E Liu_. EECS Department, UC Berkeley Technical Report, 2020. \n",
    "\n",
    "\n",
    "## License\n",
    "FLOR is licensed under the [Apache v2 License](https://www.apache.org/licenses/LICENSE-2.0).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
